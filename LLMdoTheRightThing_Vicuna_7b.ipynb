{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYDD7N9gAltyFgZBpvgpva",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c63e8c696eac4028aeb52d9a9f623e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "warning",
            "description": "Restart Runtime",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_3772a44cf82c4e0bbc7089cda1a07703",
            "style": "IPY_MODEL_4c2149f8096247708947ab80ece3f939",
            "tooltip": "Click me"
          }
        },
        "3772a44cf82c4e0bbc7089cda1a07703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c2149f8096247708947ab80ece3f939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabiomatricardi/LLMdoTheRightThing/blob/main/LLMdoTheRightThing_Vicuna_7b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4IhZMjls96U"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install ctransformers>=0.2.24\n",
        "!pip install langchain\n",
        "!pip install rich\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/TheBloke/vicuna-7B-v1.5-GGUF/resolve/main/vicuna-7b-v1.5.Q5_K_M.gguf"
      ],
      "metadata": {
        "id": "kZ8nmOwCtHZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c7c0ceb-57ea-49ab-a0aa-9ce7147b2004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-10 23:59:18--  https://huggingface.co/TheBloke/vicuna-7B-v1.5-GGUF/resolve/main/vicuna-7b-v1.5.Q5_K_M.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 18.154.227.7, 18.154.227.69, 18.154.227.87, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.154.227.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/8b/8a/8b8a084e506faaabaff764a4316992f50a72b536795224d1dd3edce626e8c695/98377262416396f9192a695e385d7e7389f8ee5979073c2d914e7e54b11ad24a?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27vicuna-7b-v1.5.Q5_K_M.gguf%3B+filename%3D%22vicuna-7b-v1.5.Q5_K_M.gguf%22%3B&Expires=1697241558&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NzI0MTU1OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy84Yi84YS84YjhhMDg0ZTUwNmZhYWFiYWZmNzY0YTQzMTY5OTJmNTBhNzJiNTM2Nzk1MjI0ZDFkZDNlZGNlNjI2ZThjNjk1Lzk4Mzc3MjYyNDE2Mzk2ZjkxOTJhNjk1ZTM4NWQ3ZTczODlmOGVlNTk3OTA3M2MyZDkxNGU3ZTU0YjExYWQyNGE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=G1XhV52US-ZUYRnfMsorm-5Xx%7ETBz9wHBGEwH-1or-KngwyKZIIivnynxuO7bvveuVYGv8mD19pXyO2tM-UKiZ78oDctxpKdE462iHM94TYhzEvgVphZOx2qc7waUXGRliz0LLCO-I72rMlHei0F0C5XWnmKVCANLK8pcWBn4TH%7ESF-k%7EkbJr7L7KDAPGy39ctjgf6FfsO9s7JfkJgs2Awngys1dLlosnhq3FV7feFrq9A0vXXNmzA84FKUWwhirr-x%7EdlIH%7EHj8VRrIOGsIyn9e6rOPRqiWTCk9plWTwDAlWCHJmUjWH9GhbNXntlvxJyyyj-i6hpRIsztlPfoh7A__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-10-10 23:59:18--  https://cdn-lfs.huggingface.co/repos/8b/8a/8b8a084e506faaabaff764a4316992f50a72b536795224d1dd3edce626e8c695/98377262416396f9192a695e385d7e7389f8ee5979073c2d914e7e54b11ad24a?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27vicuna-7b-v1.5.Q5_K_M.gguf%3B+filename%3D%22vicuna-7b-v1.5.Q5_K_M.gguf%22%3B&Expires=1697241558&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NzI0MTU1OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy84Yi84YS84YjhhMDg0ZTUwNmZhYWFiYWZmNzY0YTQzMTY5OTJmNTBhNzJiNTM2Nzk1MjI0ZDFkZDNlZGNlNjI2ZThjNjk1Lzk4Mzc3MjYyNDE2Mzk2ZjkxOTJhNjk1ZTM4NWQ3ZTczODlmOGVlNTk3OTA3M2MyZDkxNGU3ZTU0YjExYWQyNGE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=G1XhV52US-ZUYRnfMsorm-5Xx%7ETBz9wHBGEwH-1or-KngwyKZIIivnynxuO7bvveuVYGv8mD19pXyO2tM-UKiZ78oDctxpKdE462iHM94TYhzEvgVphZOx2qc7waUXGRliz0LLCO-I72rMlHei0F0C5XWnmKVCANLK8pcWBn4TH%7ESF-k%7EkbJr7L7KDAPGy39ctjgf6FfsO9s7JfkJgs2Awngys1dLlosnhq3FV7feFrq9A0vXXNmzA84FKUWwhirr-x%7EdlIH%7EHj8VRrIOGsIyn9e6rOPRqiWTCk9plWTwDAlWCHJmUjWH9GhbNXntlvxJyyyj-i6hpRIsztlPfoh7A__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.138.64.36, 108.138.64.49, 108.138.64.111, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.138.64.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4783156928 (4.5G) [binary/octet-stream]\n",
            "Saving to: ‘vicuna-7b-v1.5.Q5_K_M.gguf’\n",
            "\n",
            "vicuna-7b-v1.5.Q5_K 100%[===================>]   4.45G  46.3MB/s    in 1m 51s  \n",
            "\n",
            "2023-10-11 00:01:09 (41.2 MB/s) - ‘vicuna-7b-v1.5.Q5_K_M.gguf’ saved [4783156928/4783156928]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Restart Runtime {display-mode: \"form\"}\n",
        "import ipywidgets as widgets\n",
        "def restart(b):\n",
        "  exit()\n",
        "\n",
        "button2 = widgets.Button(\n",
        "    description='Restart Runtime',\n",
        "    disabled=False,\n",
        "    button_style='warning', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='Click me',\n",
        "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
        ")\n",
        "button2.on_click(restart)\n",
        "button2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c63e8c696eac4028aeb52d9a9f623e0b",
            "3772a44cf82c4e0bbc7089cda1a07703",
            "4c2149f8096247708947ab80ece3f939"
          ]
        },
        "outputId": "5cbe5040-603b-4789-a0c3-b1f63fba2438",
        "id": "-hsc5IfVET8S"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='warning', description='Restart Runtime', icon='check', style=ButtonStyle(), tooltip='Clic…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c63e8c696eac4028aeb52d9a9f623e0b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main routines"
      ],
      "metadata": {
        "id": "2F_gN7zvP0ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rich import print\n",
        "from tqdm.rich import trange, tqdm\n",
        "from rich import console\n",
        "from rich.panel import Panel\n",
        "from rich.text import Text\n",
        "import datetime\n",
        "import warnings\n",
        "import textwrap\n",
        "from ctransformers import AutoModelForCausalLM, AutoConfig, Config\n",
        "import datetime\n",
        "warnings.filterwarnings(action='ignore')\n",
        "from rich.console import Console\n",
        "from rich.markdown import Markdown\n",
        "console = Console(width=80)"
      ],
      "metadata": {
        "id": "ryXI1qdEzk64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf = AutoConfig(Config(temperature=0.8, repetition_penalty=1.1, batch_size=52,\n",
        "                max_new_tokens=1024, context_length=1024))\n",
        "llm = AutoModelForCausalLM.from_pretrained(\"/content/vicuna-7b-v1.5.Q5_K_M.gguf\",\n",
        "                                           model_type=\"llama\", config = conf)"
      ],
      "metadata": {
        "id": "eRJCb4FxzwVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNCTION TO LOG ALL CHAT MESSAGES INTO chathistory.txt\n",
        "def writehistory(text):\n",
        "    with open('20231011_PromptPower_Vicuna7b-history.txt', 'a') as f:\n",
        "        f.write(text)\n",
        "        f.write('\\n')\n",
        "    f.close()\n",
        "\n",
        "def vicunaQ4KM_CT(prompt):\n",
        "  from rich.markdown import Markdown\n",
        "  import datetime\n",
        "  from rich.console import Console\n",
        "  console = Console(width=80)\n",
        "  t_vicuna = f\"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\"\n",
        "  start = datetime.datetime.now()\n",
        "  console.print(f\"[italic bold bright_red]Prompt: {prompt}\")\n",
        "  answer = llm(t_vicuna, temperature = 0.7, repetition_penalty = 1.15,\n",
        "             max_new_tokens = 2048)\n",
        "  stop = datetime.datetime.now()\n",
        "  tok2 = len(llm.tokenize(t_vicuna))\n",
        "  tok1 = len(llm.tokenize(answer))\n",
        "  #console.print(f\"[italic]Number of characters in orginal prompt: {len(prompt)}\") #it works with CTransformers without Langchain\n",
        "  console.print(f\"[italic bold]Number of tokens in the  prompt: {tok2}\") #it works with CTransformers without Langchain\n",
        "  console.print(f\"[italic bold]Number of tokens in the  answer: {tok1}\")\n",
        "  console.print(Markdown(answer))\n",
        "  console.print(f\"[bold italic green] Generated by Vicuna-7b in {stop-start}\")\n",
        "  text = f\"user: {prompt}\\nVicuna-7b: {answer}\\nGenerated in {stop-start}\"\n",
        "  writehistory(text)\n",
        "  console.print(f\"[blue1] ---\")\n",
        "  return answer"
      ],
      "metadata": {
        "id": "OnXvXYtftsgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i3FFBX75fmDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TEST several Prompt templates\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "ry3If6TgCfNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "name: 'Rewrite to Formal',\n",
        "description: `This prompt rewrites your text into formal writing. It's useful for writing emails, essays, reports, and other formal documents.`,\n",
        "Template:\n",
        "```\n",
        "> \"Translate the following text into formal writing:\n",
        ">\n",
        "> ```\n",
        "> {text}\n",
        "> ```\n",
        "> \"\n",
        "```"
      ],
      "metadata": {
        "id": "b4Eadhj8CuIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"This study from March 2023 takes a simple yet novel approach to prompt engineering by automatically generating prompts based on the desired input and output.\n",
        "In a recent article I considered the future of prompt engineering, and the possibility of soft prompts (prompt tuning). I argued that user context, ambiguity and user intent all play an important role in any conversational UI.\n",
        "User intent, context, ambiguity and disambiguation are all part and parcel of any conversation.\n",
        "The question is, can this approach accelerate the process where manually wording prompts fade into the background and interaction with the LLM is based on contextual example input and output datasets?\n",
        "What I like about this approach, is that context, and user intent can be mapped, while also taking into consideration possible ambiguity.\n",
        "Yet manually crafting prompts is tedious in the sense of trying to word a prompt in such a way to engender a desired response from the LLM. Focussing on prompt engineering also does not take into consideration an array of possible user inputs.\n",
        "Data Management will always be part of LLM applications.\n",
        "APE offers an alternative approach to prompt engineering, where via input and matching output examples, prompts can be generated on the fly.\n",
        "We define “prompt engineering” as optimising the language in a prompt in order to elicit the best possible performance. Notably, this does not include prompts that chain multiple LLM queries together or give the LLM access to external tools. ~ Source\n",
        "The basic notebook below shows how Automatic Prompt Engineering (APE) can be used to generate prompts based on a small input data set, a list of expected outputs and a prompt template.\n",
        "APE performs this in two steps:\n",
        "A LLM is used to generate a set of candidate prompts.\n",
        "A prompt evaluation function considers the quality of each candidate prompt; returning the prompt with the highest evaluation score. A practical implementation is, via a human-in-the-loop approach, prompts can be marked up and marked down for use on terms of accuracy and correctness.\"\"\""
      ],
      "metadata": {
        "id": "fN898AOsDVJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.replace('\\n',' ')"
      ],
      "metadata": {
        "id": "llgccfIQDYtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "yRNDrpbRDeHG",
        "outputId": "b85313af-f4fd-483a-809c-68362d8389a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "This study from March \u001b[1;36m2023\u001b[0m takes a simple yet novel approach to prompt engineering by automatically generating \n",
              "prompts based on the desired input and output. In a recent article I considered the future of prompt engineering, \n",
              "and the possibility of soft prompts \u001b[1m(\u001b[0mprompt tuning\u001b[1m)\u001b[0m. I argued that user context, ambiguity and user intent all play\n",
              "an important role in any conversational UI. User intent, context, ambiguity and disambiguation are all part and \n",
              "parcel of any conversation. The question is, can this approach accelerate the process where manually wording \n",
              "prompts fade into the background and interaction with the LLM is based on contextual example input and output \n",
              "datasets? What I like about this approach, is that context, and user intent can be mapped, while also taking into \n",
              "consideration possible ambiguity. Yet manually crafting prompts is tedious in the sense of trying to word a prompt \n",
              "in such a way to engender a desired response from the LLM. Focussing on prompt engineering also does not take into \n",
              "consideration an array of possible user inputs. Data Management will always be part of LLM applications. APE offers\n",
              "an alternative approach to prompt engineering, where via input and matching output examples, prompts can be \n",
              "generated on the fly. We define “prompt engineering” as optimising the language in a prompt in order to elicit the \n",
              "best possible performance. Notably, this does not include prompts that chain multiple LLM queries together or give \n",
              "the LLM access to external tools. ~ Source The basic notebook below shows how Automatic Prompt Engineering \u001b[1m(\u001b[0mAPE\u001b[1m)\u001b[0m \n",
              "can be used to generate prompts based on a small input data set, a list of expected outputs and a prompt template. \n",
              "APE performs this in two steps: A LLM is used to generate a set of candidate prompts. A prompt evaluation function \n",
              "considers the quality of each candidate prompt; returning the prompt with the highest evaluation score. A practical\n",
              "implementation is, via a human-in-the-loop approach, prompts can be marked up and marked down for use on terms of \n",
              "accuracy and correctness.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">This study from March <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> takes a simple yet novel approach to prompt engineering by automatically generating \n",
              "prompts based on the desired input and output. In a recent article I considered the future of prompt engineering, \n",
              "and the possibility of soft prompts <span style=\"font-weight: bold\">(</span>prompt tuning<span style=\"font-weight: bold\">)</span>. I argued that user context, ambiguity and user intent all play\n",
              "an important role in any conversational UI. User intent, context, ambiguity and disambiguation are all part and \n",
              "parcel of any conversation. The question is, can this approach accelerate the process where manually wording \n",
              "prompts fade into the background and interaction with the LLM is based on contextual example input and output \n",
              "datasets? What I like about this approach, is that context, and user intent can be mapped, while also taking into \n",
              "consideration possible ambiguity. Yet manually crafting prompts is tedious in the sense of trying to word a prompt \n",
              "in such a way to engender a desired response from the LLM. Focussing on prompt engineering also does not take into \n",
              "consideration an array of possible user inputs. Data Management will always be part of LLM applications. APE offers\n",
              "an alternative approach to prompt engineering, where via input and matching output examples, prompts can be \n",
              "generated on the fly. We define “prompt engineering” as optimising the language in a prompt in order to elicit the \n",
              "best possible performance. Notably, this does not include prompts that chain multiple LLM queries together or give \n",
              "the LLM access to external tools. ~ Source The basic notebook below shows how Automatic Prompt Engineering <span style=\"font-weight: bold\">(</span>APE<span style=\"font-weight: bold\">)</span> \n",
              "can be used to generate prompts based on a small input data set, a list of expected outputs and a prompt template. \n",
              "APE performs this in two steps: A LLM is used to generate a set of candidate prompts. A prompt evaluation function \n",
              "considers the quality of each candidate prompt; returning the prompt with the highest evaluation score. A practical\n",
              "implementation is, via a human-in-the-loop approach, prompts can be marked up and marked down for use on terms of \n",
              "accuracy and correctness.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RewToFormal = \"\"\"\n",
        "Translate the following text into formal writing:\n",
        "\n",
        "```\n",
        "This study from March 2023 takes a simple yet novel approach to prompt engineering by automatically generating\n",
        "prompts based on the desired input and output. In a recent article I considered the future of prompt engineering,\n",
        "and the possibility of soft prompts (prompt tuning). I argued that user context, ambiguity and user intent all play\n",
        "an important role in any conversational UI. User intent, context, ambiguity and disambiguation are all part and\n",
        "parcel of any conversation. The question is, can this approach accelerate the process where manually wording\n",
        "prompts fade into the background and interaction with the LLM is based on contextual example input and output\n",
        "datasets? What I like about this approach, is that context, and user intent can be mapped, while also taking into\n",
        "consideration possible ambiguity. Yet manually crafting prompts is tedious in the sense of trying to word a prompt\n",
        "in such a way to engender a desired response from the LLM. Focussing on prompt engineering also does not take into\n",
        "consideration an array of possible user inputs. Data Management will always be part of LLM applications. APE offers\n",
        "an alternative approach to prompt engineering, where via input and matching output examples, prompts can be\n",
        "generated on the fly. We define “prompt engineering” as optimising the language in a prompt in order to elicit the\n",
        "best possible performance. Notably, this does not include prompts that chain multiple LLM queries together or give\n",
        "the LLM access to external tools. ~ Source The basic notebook below shows how Automatic Prompt Engineering (APE)\n",
        "can be used to generate prompts based on a small input data set, a list of expected outputs and a prompt template.\n",
        "APE performs this in two steps: A LLM is used to generate a set of candidate prompts. A prompt evaluation function\n",
        "considers the quality of each candidate prompt; returning the prompt with the highest evaluation score. A practical\n",
        "implementation is, via a human-in-the-loop approach, prompts can be marked up and marked down for use on terms of\n",
        "accuracy and correctness.\n",
        "```\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "X_Z9PS0ACfrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = vicunaQ4KM_CT(RewToFormal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d6oZVVMbCgJK",
        "outputId": "b1b1e2d5-78d6-4f82-e94e-abed9da7fa3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;91mPrompt: \u001b[0m\n",
              "\u001b[1;3;91mTranslate the following text into formal writing:\u001b[0m\n",
              "\n",
              "\u001b[1;3;91m```\u001b[0m\n",
              "\u001b[1;3;91mThis study from March \u001b[0m\u001b[1;3;91m2023\u001b[0m\u001b[1;3;91m takes a simple yet novel approach to prompt \u001b[0m\n",
              "\u001b[1;3;91mengineering by automatically generating \u001b[0m\n",
              "\u001b[1;3;91mprompts based on the desired input and output. In a recent article I considered \u001b[0m\n",
              "\u001b[1;3;91mthe future of prompt engineering, \u001b[0m\n",
              "\u001b[1;3;91mand the possibility of soft prompts \u001b[0m\u001b[1;3;91m(\u001b[0m\u001b[1;3;91mprompt tuning\u001b[0m\u001b[1;3;91m)\u001b[0m\u001b[1;3;91m. I argued that user context,\u001b[0m\n",
              "\u001b[1;3;91mambiguity and user intent all play\u001b[0m\n",
              "\u001b[1;3;91man important role in any conversational UI. User intent, context, ambiguity and \u001b[0m\n",
              "\u001b[1;3;91mdisambiguation are all part and \u001b[0m\n",
              "\u001b[1;3;91mparcel of any conversation. The question is, can this approach accelerate the \u001b[0m\n",
              "\u001b[1;3;91mprocess where manually wording \u001b[0m\n",
              "\u001b[1;3;91mprompts fade into the background and interaction with the LLM is based on \u001b[0m\n",
              "\u001b[1;3;91mcontextual example input and output \u001b[0m\n",
              "\u001b[1;3;91mdatasets? What I like about this approach, is that context, and user intent can \u001b[0m\n",
              "\u001b[1;3;91mbe mapped, while also taking into \u001b[0m\n",
              "\u001b[1;3;91mconsideration possible ambiguity. Yet manually crafting prompts is tedious in \u001b[0m\n",
              "\u001b[1;3;91mthe sense of trying to word a prompt \u001b[0m\n",
              "\u001b[1;3;91min such a way to engender a desired response from the LLM. Focussing on prompt \u001b[0m\n",
              "\u001b[1;3;91mengineering also does not take into \u001b[0m\n",
              "\u001b[1;3;91mconsideration an array of possible user inputs. Data Management will always be \u001b[0m\n",
              "\u001b[1;3;91mpart of LLM applications. APE offers\u001b[0m\n",
              "\u001b[1;3;91man alternative approach to prompt engineering, where via input and matching \u001b[0m\n",
              "\u001b[1;3;91moutput examples, prompts can be \u001b[0m\n",
              "\u001b[1;3;91mgenerated on the fly. We define “prompt engineering” as optimising the language \u001b[0m\n",
              "\u001b[1;3;91min a prompt in order to elicit the \u001b[0m\n",
              "\u001b[1;3;91mbest possible performance. Notably, this does not include prompts that chain \u001b[0m\n",
              "\u001b[1;3;91mmultiple LLM queries together or give \u001b[0m\n",
              "\u001b[1;3;91mthe LLM access to external tools. ~ Source The basic notebook below shows how \u001b[0m\n",
              "\u001b[1;3;91mAutomatic Prompt Engineering \u001b[0m\u001b[1;3;91m(\u001b[0m\u001b[1;3;91mAPE\u001b[0m\u001b[1;3;91m)\u001b[0m\u001b[1;3;91m \u001b[0m\n",
              "\u001b[1;3;91mcan be used to generate prompts based on a small input data set, a list of \u001b[0m\n",
              "\u001b[1;3;91mexpected outputs and a prompt template. \u001b[0m\n",
              "\u001b[1;3;91mAPE performs this in two steps: A LLM is used to generate a set of candidate \u001b[0m\n",
              "\u001b[1;3;91mprompts. A prompt evaluation function \u001b[0m\n",
              "\u001b[1;3;91mconsiders the quality of each candidate prompt; returning the prompt with the \u001b[0m\n",
              "\u001b[1;3;91mhighest evaluation score. A practical\u001b[0m\n",
              "\u001b[1;3;91mimplementation is, via a human-in-the-loop approach, prompts can be marked up \u001b[0m\n",
              "\u001b[1;3;91mand marked down for use on terms of \u001b[0m\n",
              "\u001b[1;3;91maccuracy and correctness.\u001b[0m\n",
              "\u001b[1;3;91m```\u001b[0m\n",
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Prompt: </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Translate the following text into formal writing:</span>\n",
              "\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">```</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">This study from March 2023 takes a simple yet novel approach to prompt </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">engineering by automatically generating </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">prompts based on the desired input and output. In a recent article I considered </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">the future of prompt engineering, </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">and the possibility of soft prompts (prompt tuning). I argued that user context,</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">ambiguity and user intent all play</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">an important role in any conversational UI. User intent, context, ambiguity and </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">disambiguation are all part and </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">parcel of any conversation. The question is, can this approach accelerate the </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">process where manually wording </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">prompts fade into the background and interaction with the LLM is based on </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">contextual example input and output </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">datasets? What I like about this approach, is that context, and user intent can </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">be mapped, while also taking into </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">consideration possible ambiguity. Yet manually crafting prompts is tedious in </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">the sense of trying to word a prompt </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">in such a way to engender a desired response from the LLM. Focussing on prompt </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">engineering also does not take into </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">consideration an array of possible user inputs. Data Management will always be </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">part of LLM applications. APE offers</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">an alternative approach to prompt engineering, where via input and matching </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">output examples, prompts can be </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">generated on the fly. We define “prompt engineering” as optimising the language </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">in a prompt in order to elicit the </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">best possible performance. Notably, this does not include prompts that chain </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">multiple LLM queries together or give </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">the LLM access to external tools. ~ Source The basic notebook below shows how </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Automatic Prompt Engineering (APE) </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">can be used to generate prompts based on a small input data set, a list of </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">expected outputs and a prompt template. </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">APE performs this in two steps: A LLM is used to generate a set of candidate </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">prompts. A prompt evaluation function </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">considers the quality of each candidate prompt; returning the prompt with the </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">highest evaluation score. A practical</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">implementation is, via a human-in-the-loop approach, prompts can be marked up </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">and marked down for use on terms of </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">accuracy and correctness.</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">```</span>\n",
              "\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3mNumber of tokens in the  prompt: \u001b[0m\u001b[1;3;36m526\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Number of tokens in the  prompt: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">526</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3mNumber of tokens in the  answer: \u001b[0m\u001b[1;3;36m460\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Number of tokens in the  answer: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">460</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "This study conducted in March 2023 adopts an innovative methodology for         \n",
              "generating prompts by automatically creating them based on the desired input and\n",
              "output. In a recent article, I explored the future prospects of prompt          \n",
              "engineering, specifically focusing on soft prompts (prompt tuning), as well as  \n",
              "considering user context, ambiguity, and intent in conversational user          \n",
              "interfaces. It is essential to understand that these factors play a crucial role\n",
              "in any conversation. Context, user intent, ambiguity, and disambiguation are all\n",
              "interconnected aspects of communication. The primary objective is whether this  \n",
              "approach can accelerate the process where manually crafting prompts gradually   \n",
              "becomes obsolete, and interactions with the language model (LLM) rely on        \n",
              "contextual examples for input and output datasets. One advantage of this        \n",
              "methodology is that it allows for mapping user intent and context while         \n",
              "accounting for potential ambiguity. However, manually composing prompts can be  \n",
              "time-consuming, as it requires crafting a prompt to elicit the desired response \n",
              "from the LLM. In addition, focusing on prompt engineering does not address a    \n",
              "wide range of possible user inputs. Data management will always be an integral  \n",
              "part of LLM applications. The Adaptive Prompt Engineering (APE) approach offers \n",
              "an alternative method for generating prompts by matching output examples based  \n",
              "on input and creating prompts on the fly. We define \"prompt engineering\" as     \n",
              "optimizing the language used in a prompt to elicit superior performance.        \n",
              "Notably, this does not include prompts that concatenate multiple LLM queries or \n",
              "grant the LLM access to external tools.                                         \n",
              "\n",
              "The basic notebook provided below illustrates how Automatic Prompt Engineering  \n",
              "(APE) can be employed to generate prompts using a small input dataset, a list of\n",
              "expected outputs, and a template-based prompt. This process involves two steps: \n",
              "utilizing a language model to produce a set of candidate prompts, followed by a \n",
              "prompt evaluation function assessing the quality of each candidate prompt;      \n",
              "selecting the prompt with the highest evaluation score. In practice, this can be\n",
              "achieved through a human-in-the-loop approach, where prompts are marked up or   \n",
              "down based on their accuracy and correctness.                                   \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">This study conducted in March 2023 adopts an innovative methodology for         \n",
              "generating prompts by automatically creating them based on the desired input and\n",
              "output. In a recent article, I explored the future prospects of prompt          \n",
              "engineering, specifically focusing on soft prompts (prompt tuning), as well as  \n",
              "considering user context, ambiguity, and intent in conversational user          \n",
              "interfaces. It is essential to understand that these factors play a crucial role\n",
              "in any conversation. Context, user intent, ambiguity, and disambiguation are all\n",
              "interconnected aspects of communication. The primary objective is whether this  \n",
              "approach can accelerate the process where manually crafting prompts gradually   \n",
              "becomes obsolete, and interactions with the language model (LLM) rely on        \n",
              "contextual examples for input and output datasets. One advantage of this        \n",
              "methodology is that it allows for mapping user intent and context while         \n",
              "accounting for potential ambiguity. However, manually composing prompts can be  \n",
              "time-consuming, as it requires crafting a prompt to elicit the desired response \n",
              "from the LLM. In addition, focusing on prompt engineering does not address a    \n",
              "wide range of possible user inputs. Data management will always be an integral  \n",
              "part of LLM applications. The Adaptive Prompt Engineering (APE) approach offers \n",
              "an alternative method for generating prompts by matching output examples based  \n",
              "on input and creating prompts on the fly. We define \"prompt engineering\" as     \n",
              "optimizing the language used in a prompt to elicit superior performance.        \n",
              "Notably, this does not include prompts that concatenate multiple LLM queries or \n",
              "grant the LLM access to external tools.                                         \n",
              "\n",
              "The basic notebook provided below illustrates how Automatic Prompt Engineering  \n",
              "(APE) can be employed to generate prompts using a small input dataset, a list of\n",
              "expected outputs, and a template-based prompt. This process involves two steps: \n",
              "utilizing a language model to produce a set of candidate prompts, followed by a \n",
              "prompt evaluation function assessing the quality of each candidate prompt;      \n",
              "selecting the prompt with the highest evaluation score. In practice, this can be\n",
              "achieved through a human-in-the-loop approach, where prompts are marked up or   \n",
              "down based on their accuracy and correctness.                                   \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;32m Generated by Vicuna-7b in \u001b[0m\u001b[1;3;32m0:09:18\u001b[0m\u001b[1;3;32m.\u001b[0m\u001b[1;3;32m140666\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold; font-style: italic\"> Generated by Vicuna-7b in 0:09:18.140666</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;5;21m ---\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0000ff; text-decoration-color: #0000ff\"> ---</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### name: 'Rewrite to Cool',\n",
        "description: `This prompt rewrites your text to make it more cool and elegant. It's useful for making your writing cooler and have some style in it.`,\n",
        "Template:\n",
        "\n",
        ">\"Rewrite the following text to make it more cool and elegant:\n",
        ">\n",
        ">```\n",
        ">{text}\n",
        ">```\n",
        ">\"\n",
        "\n",
        "\n",
        "### name: 'Proofread',\n",
        "description: `This prompt proofreads your text and suggests edits in it. It's useful for making your writing more professional and correct.`,\n",
        "Template:\n",
        ">\"Proofread and correct the following text and suggest improvements. If you >don't find and errors, just say \"No errors found\".:\n",
        ">\n",
        ">```\n",
        ">{text}\n",
        ">```\n",
        ">\"\n",
        "\n",
        "\n",
        "### name: 'Proofread and Correct',\n",
        "description: `This prompt proofreads your text and corrects any mistakes in it. It's useful for making your writing more professional and correct.`,\n",
        "Template:\n",
        ">\"Proofread and correct the following text and rewrite the corrected version. >If you don't find and errors, just say \"No errors found\". Don't use any >punctuation around the text:\n",
        ">\n",
        ">```\n",
        ">{text}\n",
        ">```\n",
        ">\"\n",
        "\n"
      ],
      "metadata": {
        "id": "l_WccTYnFN6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RewToCool = \"\"\"\n",
        "Rewrite the following text to make it more cool and elegant:\n",
        "\n",
        "```\n",
        "This study from March 2023 takes a simple yet novel approach to prompt engineering by automatically generating\n",
        "prompts based on the desired input and output. In a recent article I considered the future of prompt engineering,\n",
        "and the possibility of soft prompts (prompt tuning). I argued that user context, ambiguity and user intent all play\n",
        "an important role in any conversational UI. User intent, context, ambiguity and disambiguation are all part and\n",
        "parcel of any conversation. The question is, can this approach accelerate the process where manually wording\n",
        "prompts fade into the background and interaction with the LLM is based on contextual example input and output\n",
        "datasets? What I like about this approach, is that context, and user intent can be mapped, while also taking into\n",
        "consideration possible ambiguity. Yet manually crafting prompts is tedious in the sense of trying to word a prompt\n",
        "in such a way to engender a desired response from the LLM. Focussing on prompt engineering also does not take into\n",
        "consideration an array of possible user inputs. Data Management will always be part of LLM applications. APE offers\n",
        "an alternative approach to prompt engineering, where via input and matching output examples, prompts can be\n",
        "generated on the fly. We define “prompt engineering” as optimising the language in a prompt in order to elicit the\n",
        "best possible performance. Notably, this does not include prompts that chain multiple LLM queries together or give\n",
        "the LLM access to external tools. ~ Source The basic notebook below shows how Automatic Prompt Engineering (APE)\n",
        "can be used to generate prompts based on a small input data set, a list of expected outputs and a prompt template.\n",
        "APE performs this in two steps: A LLM is used to generate a set of candidate prompts. A prompt evaluation function\n",
        "considers the quality of each candidate prompt; returning the prompt with the highest evaluation score. A practical\n",
        "implementation is, via a human-in-the-loop approach, prompts can be marked up and marked down for use on terms of\n",
        "accuracy and correctness.\n",
        "```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "PNRrVee3GIhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2 = vicunaQ4KM_CT(RewToCool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zFh4q9-tGIaj",
        "outputId": "759a5d61-24dc-4512-8c36-1e9cdbbbf72e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;91mPrompt: \u001b[0m\n",
              "\u001b[1;3;91mRewrite the following text to make it more cool and elegant:\u001b[0m\n",
              "\n",
              "\u001b[1;3;91m```\u001b[0m\n",
              "\u001b[1;3;91mThis study from March \u001b[0m\u001b[1;3;91m2023\u001b[0m\u001b[1;3;91m takes a simple yet novel approach to prompt \u001b[0m\n",
              "\u001b[1;3;91mengineering by automatically generating \u001b[0m\n",
              "\u001b[1;3;91mprompts based on the desired input and output. In a recent article I considered \u001b[0m\n",
              "\u001b[1;3;91mthe future of prompt engineering, \u001b[0m\n",
              "\u001b[1;3;91mand the possibility of soft prompts \u001b[0m\u001b[1;3;91m(\u001b[0m\u001b[1;3;91mprompt tuning\u001b[0m\u001b[1;3;91m)\u001b[0m\u001b[1;3;91m. I argued that user context,\u001b[0m\n",
              "\u001b[1;3;91mambiguity and user intent all play\u001b[0m\n",
              "\u001b[1;3;91man important role in any conversational UI. User intent, context, ambiguity and \u001b[0m\n",
              "\u001b[1;3;91mdisambiguation are all part and \u001b[0m\n",
              "\u001b[1;3;91mparcel of any conversation. The question is, can this approach accelerate the \u001b[0m\n",
              "\u001b[1;3;91mprocess where manually wording \u001b[0m\n",
              "\u001b[1;3;91mprompts fade into the background and interaction with the LLM is based on \u001b[0m\n",
              "\u001b[1;3;91mcontextual example input and output \u001b[0m\n",
              "\u001b[1;3;91mdatasets? What I like about this approach, is that context, and user intent can \u001b[0m\n",
              "\u001b[1;3;91mbe mapped, while also taking into \u001b[0m\n",
              "\u001b[1;3;91mconsideration possible ambiguity. Yet manually crafting prompts is tedious in \u001b[0m\n",
              "\u001b[1;3;91mthe sense of trying to word a prompt \u001b[0m\n",
              "\u001b[1;3;91min such a way to engender a desired response from the LLM. Focussing on prompt \u001b[0m\n",
              "\u001b[1;3;91mengineering also does not take into \u001b[0m\n",
              "\u001b[1;3;91mconsideration an array of possible user inputs. Data Management will always be \u001b[0m\n",
              "\u001b[1;3;91mpart of LLM applications. APE offers\u001b[0m\n",
              "\u001b[1;3;91man alternative approach to prompt engineering, where via input and matching \u001b[0m\n",
              "\u001b[1;3;91moutput examples, prompts can be \u001b[0m\n",
              "\u001b[1;3;91mgenerated on the fly. We define “prompt engineering” as optimising the language \u001b[0m\n",
              "\u001b[1;3;91min a prompt in order to elicit the \u001b[0m\n",
              "\u001b[1;3;91mbest possible performance. Notably, this does not include prompts that chain \u001b[0m\n",
              "\u001b[1;3;91mmultiple LLM queries together or give \u001b[0m\n",
              "\u001b[1;3;91mthe LLM access to external tools. ~ Source The basic notebook below shows how \u001b[0m\n",
              "\u001b[1;3;91mAutomatic Prompt Engineering \u001b[0m\u001b[1;3;91m(\u001b[0m\u001b[1;3;91mAPE\u001b[0m\u001b[1;3;91m)\u001b[0m\u001b[1;3;91m \u001b[0m\n",
              "\u001b[1;3;91mcan be used to generate prompts based on a small input data set, a list of \u001b[0m\n",
              "\u001b[1;3;91mexpected outputs and a prompt template. \u001b[0m\n",
              "\u001b[1;3;91mAPE performs this in two steps: A LLM is used to generate a set of candidate \u001b[0m\n",
              "\u001b[1;3;91mprompts. A prompt evaluation function \u001b[0m\n",
              "\u001b[1;3;91mconsiders the quality of each candidate prompt; returning the prompt with the \u001b[0m\n",
              "\u001b[1;3;91mhighest evaluation score. A practical\u001b[0m\n",
              "\u001b[1;3;91mimplementation is, via a human-in-the-loop approach, prompts can be marked up \u001b[0m\n",
              "\u001b[1;3;91mand marked down for use on terms of \u001b[0m\n",
              "\u001b[1;3;91maccuracy and correctness.\u001b[0m\n",
              "\u001b[1;3;91m```\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Prompt: </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Rewrite the following text to make it more cool and elegant:</span>\n",
              "\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">```</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">This study from March 2023 takes a simple yet novel approach to prompt </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">engineering by automatically generating </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">prompts based on the desired input and output. In a recent article I considered </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">the future of prompt engineering, </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">and the possibility of soft prompts (prompt tuning). I argued that user context,</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">ambiguity and user intent all play</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">an important role in any conversational UI. User intent, context, ambiguity and </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">disambiguation are all part and </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">parcel of any conversation. The question is, can this approach accelerate the </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">process where manually wording </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">prompts fade into the background and interaction with the LLM is based on </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">contextual example input and output </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">datasets? What I like about this approach, is that context, and user intent can </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">be mapped, while also taking into </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">consideration possible ambiguity. Yet manually crafting prompts is tedious in </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">the sense of trying to word a prompt </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">in such a way to engender a desired response from the LLM. Focussing on prompt </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">engineering also does not take into </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">consideration an array of possible user inputs. Data Management will always be </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">part of LLM applications. APE offers</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">an alternative approach to prompt engineering, where via input and matching </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">output examples, prompts can be </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">generated on the fly. We define “prompt engineering” as optimising the language </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">in a prompt in order to elicit the </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">best possible performance. Notably, this does not include prompts that chain </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">multiple LLM queries together or give </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">the LLM access to external tools. ~ Source The basic notebook below shows how </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Automatic Prompt Engineering (APE) </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">can be used to generate prompts based on a small input data set, a list of </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">expected outputs and a prompt template. </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">APE performs this in two steps: A LLM is used to generate a set of candidate </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">prompts. A prompt evaluation function </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">considers the quality of each candidate prompt; returning the prompt with the </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">highest evaluation score. A practical</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">implementation is, via a human-in-the-loop approach, prompts can be marked up </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">and marked down for use on terms of </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">accuracy and correctness.</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">```</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3mNumber of tokens in the  prompt: \u001b[0m\u001b[1;3;36m529\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Number of tokens in the  prompt: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">529</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3mNumber of tokens in the  answer: \u001b[0m\u001b[1;3;36m353\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Number of tokens in the  answer: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">353</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "In this innovative study conducted in March 2023, we employ an unconventional   \n",
              "yet effective method of prompt engineering by automatically generating prompts  \n",
              "based on desired input and output. Recently, I explored the future of prompt    \n",
              "engineering, including the potential for soft prompts (prompt tuning), and      \n",
              "emphasized the importance of user context, ambiguity, intent, and disambiguation\n",
              "in any conversational interface.                                                \n",
              "\n",
              "Our approach seamlessly merges context, user intent, and possible ambiguities to\n",
              "streamline the process of manually crafted prompts while enhancing interaction  \n",
              "with large language models (LLMs). This methodology enables a more efficient way\n",
              "of generating prompts that are tailored to specific input-output datasets.      \n",
              "\n",
              "By using Automatic Prompt Engineering (APE), we can generate prompts on-the-fly \n",
              "through input and matching output examples. APE optimizes the language in a     \n",
              "prompt, aiming for the best possible performance without involving multiple LLM \n",
              "queries or granting external access to the LLM. This novel approach offers a    \n",
              "refreshing perspective on prompt engineering by focusing on the context of user \n",
              "intent while considering ambiguity as an essential factor in any conversation.  \n",
              "\n",
              "The basic notebook below illustrates how APE can generate prompts based on a    \n",
              "small input dataset, a list of expected outputs, and a prompt template:         \n",
              "\n",
              "\u001b[1;33m 1 \u001b[0mAn LLM generates candidate prompts.                                          \n",
              "\u001b[1;33m 2 \u001b[0mA prompt evaluation function assesses the quality of each candidate prompt by\n",
              "\u001b[1;33m   \u001b[0mreturning the one with the highest evaluation score.                         \n",
              "\u001b[1;33m 3 \u001b[0mIn practice, human-in-the-loop approach allows for marking up or down prompts\n",
              "\u001b[1;33m   \u001b[0mbased on accuracy and correctness.                                           \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">In this innovative study conducted in March 2023, we employ an unconventional   \n",
              "yet effective method of prompt engineering by automatically generating prompts  \n",
              "based on desired input and output. Recently, I explored the future of prompt    \n",
              "engineering, including the potential for soft prompts (prompt tuning), and      \n",
              "emphasized the importance of user context, ambiguity, intent, and disambiguation\n",
              "in any conversational interface.                                                \n",
              "\n",
              "Our approach seamlessly merges context, user intent, and possible ambiguities to\n",
              "streamline the process of manually crafted prompts while enhancing interaction  \n",
              "with large language models (LLMs). This methodology enables a more efficient way\n",
              "of generating prompts that are tailored to specific input-output datasets.      \n",
              "\n",
              "By using Automatic Prompt Engineering (APE), we can generate prompts on-the-fly \n",
              "through input and matching output examples. APE optimizes the language in a     \n",
              "prompt, aiming for the best possible performance without involving multiple LLM \n",
              "queries or granting external access to the LLM. This novel approach offers a    \n",
              "refreshing perspective on prompt engineering by focusing on the context of user \n",
              "intent while considering ambiguity as an essential factor in any conversation.  \n",
              "\n",
              "The basic notebook below illustrates how APE can generate prompts based on a    \n",
              "small input dataset, a list of expected outputs, and a prompt template:         \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span>An LLM generates candidate prompts.                                          \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span>A prompt evaluation function assesses the quality of each candidate prompt by\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>returning the one with the highest evaluation score.                         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span>In practice, human-in-the-loop approach allows for marking up or down prompts\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>based on accuracy and correctness.                                           \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;32m Generated by Vicuna-7b in \u001b[0m\u001b[1;3;32m0:07:52\u001b[0m\u001b[1;3;32m.\u001b[0m\u001b[1;3;32m909556\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold; font-style: italic\"> Generated by Vicuna-7b in 0:07:52.909556</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;5;21m ---\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0000ff; text-decoration-color: #0000ff\"> ---</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### name: 'Question with Reasoning',\n",
        "description: `This prompt guides critical thinking by instructing the LLM to provide it's initial thoughts, critique them, and provide a final answer.`,\n",
        "Template:\n",
        "```\n",
        "\"{question}\n",
        "\n",
        "Reply in the following pattern:\n",
        "THOUGHT: // Your thought here\n",
        "CRITICISM: // Criticism of your thought\n",
        "ANSWER: // Your final answer\"\n",
        "```\n"
      ],
      "metadata": {
        "id": "2cT56wJJGrUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QuesWithReas = \"\"\"\n",
        "Will Artificial Intelligence replace humans in the near future?\n",
        "\n",
        "Reply in the following pattern:\n",
        "THOUGHT: // Your thought here\n",
        "CRITICISM: // Criticism of your thought\n",
        "ANSWER: // Your final answer\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rflbLqIoGIXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt3 = vicunaQ4KM_CT(QuesWithReas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "0ufvXgsIGsW8",
        "outputId": "9647cf38-85f8-491f-baf8-3d3788d24ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;91mPrompt: \u001b[0m\n",
              "\u001b[1;3;91mWill Artificial Intelligence replace humans in the near future?\u001b[0m\n",
              "\n",
              "\u001b[1;3;91mReply in the following pattern:\u001b[0m\n",
              "\u001b[1;3;91mTHOUGHT: \u001b[0m\u001b[1;3;91m/\u001b[0m\u001b[1;3;91m/\u001b[0m\u001b[1;3;91m Your thought here\u001b[0m\n",
              "\u001b[1;3;91mCRITICISM: \u001b[0m\u001b[1;3;91m/\u001b[0m\u001b[1;3;91m/\u001b[0m\u001b[1;3;91m Criticism of your thought\u001b[0m\n",
              "\u001b[1;3;91mANSWER: \u001b[0m\u001b[1;3;91m/\u001b[0m\u001b[1;3;91m/\u001b[0m\u001b[1;3;91m Your final answer\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Prompt: </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Will Artificial Intelligence replace humans in the near future?</span>\n",
              "\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Reply in the following pattern:</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">THOUGHT: // Your thought here</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">CRITICISM: // Criticism of your thought</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">ANSWER: // Your final answer</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3mNumber of tokens in the  prompt: \u001b[0m\u001b[1;3;36m97\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Number of tokens in the  prompt: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">97</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3mNumber of tokens in the  answer: \u001b[0m\u001b[1;3;36m179\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Number of tokens in the  answer: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">179</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "THOUGHT: Artificial intelligence is advancing rapidly, and it's possible that it\n",
              "may eventually surpass human capabilities in certain areas. However, it's       \n",
              "unlikely that AI will completely replace humans in the near future.             \n",
              "\n",
              "CRITICISM: This thought overlooks the potential ethical implications of advanced\n",
              "AI, such as the risk of job displacement and loss of privacy for individuals. It\n",
              "also doesn't consider the possibility of AI being used to enhance human         \n",
              "capabilities rather than replace them.                                          \n",
              "\n",
              "ANSWER: While it's true that AI has made significant progress in recent years,  \n",
              "it's unlikely to completely replace humans in the near future. Instead, we      \n",
              "should focus on developing AI that complements and enhances human abilities     \n",
              "while also addressing ethical concerns related to its deployment.               \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">THOUGHT: Artificial intelligence is advancing rapidly, and it's possible that it\n",
              "may eventually surpass human capabilities in certain areas. However, it's       \n",
              "unlikely that AI will completely replace humans in the near future.             \n",
              "\n",
              "CRITICISM: This thought overlooks the potential ethical implications of advanced\n",
              "AI, such as the risk of job displacement and loss of privacy for individuals. It\n",
              "also doesn't consider the possibility of AI being used to enhance human         \n",
              "capabilities rather than replace them.                                          \n",
              "\n",
              "ANSWER: While it's true that AI has made significant progress in recent years,  \n",
              "it's unlikely to completely replace humans in the near future. Instead, we      \n",
              "should focus on developing AI that complements and enhances human abilities     \n",
              "while also addressing ethical concerns related to its deployment.               \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;32m Generated by Vicuna-7b in \u001b[0m\u001b[1;3;32m0:02:38\u001b[0m\u001b[1;3;32m.\u001b[0m\u001b[1;3;32m361321\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold; font-style: italic\"> Generated by Vicuna-7b in 0:02:38.361321</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;5;21m ---\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0000ff; text-decoration-color: #0000ff\"> ---</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### question with context\n",
        "```\n",
        "\"\"\"Answer the question based on the context below. Keep the answer short. Respond \"Unsure about answer\" if not sure about the answer.\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "H6P6N96GRiEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QuestWithCont = \"\"\"Answer the question based on the context below. Keep the answer short. Respond \"Unsure about answer\" if not sure about the answer.\n",
        "\n",
        "Context: This study from March 2023 takes a simple yet novel approach to prompt engineering by automatically generating\n",
        "prompts based on the desired input and output. In a recent article I considered the future of prompt engineering,\n",
        "and the possibility of soft prompts (prompt tuning). I argued that user context, ambiguity and user intent all play\n",
        "an important role in any conversational UI. User intent, context, ambiguity and disambiguation are all part and\n",
        "parcel of any conversation. The question is, can this approach accelerate the process where manually wording\n",
        "prompts fade into the background and interaction with the LLM is based on contextual example input and output\n",
        "datasets? What I like about this approach, is that context, and user intent can be mapped, while also taking into\n",
        "consideration possible ambiguity. Yet manually crafting prompts is tedious in the sense of trying to word a prompt\n",
        "in such a way to engender a desired response from the LLM. Focussing on prompt engineering also does not take into\n",
        "consideration an array of possible user inputs. Data Management will always be part of LLM applications. APE offers\n",
        "an alternative approach to prompt engineering, where via input and matching output examples, prompts can be\n",
        "generated on the fly. We define “prompt engineering” as optimising the language in a prompt in order to elicit the\n",
        "best possible performance. Notably, this does not include prompts that chain multiple LLM queries together or give\n",
        "the LLM access to external tools. ~ Source The basic notebook below shows how Automatic Prompt Engineering (APE)\n",
        "can be used to generate prompts based on a small input data set, a list of expected outputs and a prompt template.\n",
        "APE performs this in two steps: A LLM is used to generate a set of candidate prompts. A prompt evaluation function\n",
        "considers the quality of each candidate prompt; returning the prompt with the highest evaluation score. A practical\n",
        "implementation is, via a human-in-the-loop approach, prompts can be marked up and marked down for use on terms of\n",
        "accuracy and correctness.\n",
        "\n",
        "Question: What is APE?\n",
        "\n",
        "Answer:\"\"\""
      ],
      "metadata": {
        "id": "6gBN8v6CCf_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt4 = vicunaQ4KM_CT(QuestWithCont)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "id": "KWZ4cWwlR9bC",
        "outputId": "008a7483-537d-49d1-804c-5e27e55f6a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;91mPrompt: Answer the question based on the context below. Keep the answer short. \u001b[0m\n",
              "\u001b[1;3;91mRespond \u001b[0m\u001b[1;3;91m\"Unsure about answer\"\u001b[0m\u001b[1;3;91m if not sure about the answer.\u001b[0m\n",
              "\n",
              "\u001b[1;3;91mContext: This study from March \u001b[0m\u001b[1;3;91m2023\u001b[0m\u001b[1;3;91m takes a simple yet novel approach to prompt \u001b[0m\n",
              "\u001b[1;3;91mengineering by automatically generating \u001b[0m\n",
              "\u001b[1;3;91mprompts based on the desired input and output. In a recent article I considered \u001b[0m\n",
              "\u001b[1;3;91mthe future of prompt engineering, \u001b[0m\n",
              "\u001b[1;3;91mand the possibility of soft prompts \u001b[0m\u001b[1;3;91m(\u001b[0m\u001b[1;3;91mprompt tuning\u001b[0m\u001b[1;3;91m)\u001b[0m\u001b[1;3;91m. I argued that user context,\u001b[0m\n",
              "\u001b[1;3;91mambiguity and user intent all play\u001b[0m\n",
              "\u001b[1;3;91man important role in any conversational UI. User intent, context, ambiguity and \u001b[0m\n",
              "\u001b[1;3;91mdisambiguation are all part and \u001b[0m\n",
              "\u001b[1;3;91mparcel of any conversation. The question is, can this approach accelerate the \u001b[0m\n",
              "\u001b[1;3;91mprocess where manually wording \u001b[0m\n",
              "\u001b[1;3;91mprompts fade into the background and interaction with the LLM is based on \u001b[0m\n",
              "\u001b[1;3;91mcontextual example input and output \u001b[0m\n",
              "\u001b[1;3;91mdatasets? What I like about this approach, is that context, and user intent can \u001b[0m\n",
              "\u001b[1;3;91mbe mapped, while also taking into \u001b[0m\n",
              "\u001b[1;3;91mconsideration possible ambiguity. Yet manually crafting prompts is tedious in \u001b[0m\n",
              "\u001b[1;3;91mthe sense of trying to word a prompt \u001b[0m\n",
              "\u001b[1;3;91min such a way to engender a desired response from the LLM. Focussing on prompt \u001b[0m\n",
              "\u001b[1;3;91mengineering also does not take into \u001b[0m\n",
              "\u001b[1;3;91mconsideration an array of possible user inputs. Data Management will always be \u001b[0m\n",
              "\u001b[1;3;91mpart of LLM applications. APE offers\u001b[0m\n",
              "\u001b[1;3;91man alternative approach to prompt engineering, where via input and matching \u001b[0m\n",
              "\u001b[1;3;91moutput examples, prompts can be \u001b[0m\n",
              "\u001b[1;3;91mgenerated on the fly. We define “prompt engineering” as optimising the language \u001b[0m\n",
              "\u001b[1;3;91min a prompt in order to elicit the \u001b[0m\n",
              "\u001b[1;3;91mbest possible performance. Notably, this does not include prompts that chain \u001b[0m\n",
              "\u001b[1;3;91mmultiple LLM queries together or give \u001b[0m\n",
              "\u001b[1;3;91mthe LLM access to external tools. ~ Source The basic notebook below shows how \u001b[0m\n",
              "\u001b[1;3;91mAutomatic Prompt Engineering \u001b[0m\u001b[1;3;91m(\u001b[0m\u001b[1;3;91mAPE\u001b[0m\u001b[1;3;91m)\u001b[0m\u001b[1;3;91m \u001b[0m\n",
              "\u001b[1;3;91mcan be used to generate prompts based on a small input data set, a list of \u001b[0m\n",
              "\u001b[1;3;91mexpected outputs and a prompt template. \u001b[0m\n",
              "\u001b[1;3;91mAPE performs this in two steps: A LLM is used to generate a set of candidate \u001b[0m\n",
              "\u001b[1;3;91mprompts. A prompt evaluation function \u001b[0m\n",
              "\u001b[1;3;91mconsiders the quality of each candidate prompt; returning the prompt with the \u001b[0m\n",
              "\u001b[1;3;91mhighest evaluation score. A practical\u001b[0m\n",
              "\u001b[1;3;91mimplementation is, via a human-in-the-loop approach, prompts can be marked up \u001b[0m\n",
              "\u001b[1;3;91mand marked down for use on terms of \u001b[0m\n",
              "\u001b[1;3;91maccuracy and correctness.\u001b[0m\n",
              "\n",
              "\u001b[1;3;91mQuestion: What is APE?\u001b[0m\n",
              "\n",
              "\u001b[1;3;91mAnswer:\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Prompt: Answer the question based on the context below. Keep the answer short. </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Respond \"Unsure about answer\" if not sure about the answer.</span>\n",
              "\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Context: This study from March 2023 takes a simple yet novel approach to prompt </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">engineering by automatically generating </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">prompts based on the desired input and output. In a recent article I considered </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">the future of prompt engineering, </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">and the possibility of soft prompts (prompt tuning). I argued that user context,</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">ambiguity and user intent all play</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">an important role in any conversational UI. User intent, context, ambiguity and </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">disambiguation are all part and </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">parcel of any conversation. The question is, can this approach accelerate the </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">process where manually wording </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">prompts fade into the background and interaction with the LLM is based on </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">contextual example input and output </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">datasets? What I like about this approach, is that context, and user intent can </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">be mapped, while also taking into </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">consideration possible ambiguity. Yet manually crafting prompts is tedious in </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">the sense of trying to word a prompt </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">in such a way to engender a desired response from the LLM. Focussing on prompt </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">engineering also does not take into </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">consideration an array of possible user inputs. Data Management will always be </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">part of LLM applications. APE offers</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">an alternative approach to prompt engineering, where via input and matching </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">output examples, prompts can be </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">generated on the fly. We define “prompt engineering” as optimising the language </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">in a prompt in order to elicit the </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">best possible performance. Notably, this does not include prompts that chain </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">multiple LLM queries together or give </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">the LLM access to external tools. ~ Source The basic notebook below shows how </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Automatic Prompt Engineering (APE) </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">can be used to generate prompts based on a small input data set, a list of </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">expected outputs and a prompt template. </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">APE performs this in two steps: A LLM is used to generate a set of candidate </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">prompts. A prompt evaluation function </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">considers the quality of each candidate prompt; returning the prompt with the </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">highest evaluation score. A practical</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">implementation is, via a human-in-the-loop approach, prompts can be marked up </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">and marked down for use on terms of </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">accuracy and correctness.</span>\n",
              "\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Question: What is APE?</span>\n",
              "\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Answer:</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3mNumber of tokens in the  prompt: \u001b[0m\u001b[1;3;36m553\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Number of tokens in the  prompt: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">553</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3mNumber of tokens in the  answer: \u001b[0m\u001b[1;3;36m56\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Number of tokens in the  answer: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">56</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Automatic Prompt Engineering (APE) is an approach to prompt engineering that    \n",
              "generates prompts based on a desired input, output, and a template. It uses     \n",
              "natural language processing techniques to generate candidate prompts, which are \n",
              "evaluated for quality by a prompt evaluation function.                          \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Automatic Prompt Engineering (APE) is an approach to prompt engineering that    \n",
              "generates prompts based on a desired input, output, and a template. It uses     \n",
              "natural language processing techniques to generate candidate prompts, which are \n",
              "evaluated for quality by a prompt evaluation function.                          \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;32m Generated by Vicuna-7b in \u001b[0m\u001b[1;3;32m0:04:53\u001b[0m\u001b[1;3;32m.\u001b[0m\u001b[1;3;32m860025\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold; font-style: italic\"> Generated by Vicuna-7b in 0:04:53.860025</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;5;21m ---\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0000ff; text-decoration-color: #0000ff\"> ---</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### name: 'Zero-Shot CoT',\n",
        "// https://arxiv.org/abs/2205.11916\n",
        "description: `Chain-of-thought (CoT) prompting enables complex reasoning capabilities through intermediate reasoning steps. Useful for more complex arithmetic, commonsense, and symbolic reasoning tasks.`,\n",
        "paper: 'https://arxiv.org/abs/2205.11916',\n",
        "Template:\n",
        "```\n",
        "\"\"\"{question}\n",
        "\n",
        "Let's think step by step.\"\"\"\"\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### name: 'Zero-Shot CoT (APE)',\n",
        "// https://arxiv.org/abs/2211.01910\n",
        "description: `Chain-of-thought (CoT) prompt discovered by automatic prompt engineer (APE) which is better than the human engineered zero-shot CoT prompt.`,\n",
        "paper: 'https://arxiv.org/abs/2211.01910',\n",
        "Template:\n",
        "```\n",
        "\"\"\"{question}\n",
        "\n",
        "Let's work this out in a step by step way to be sure we have the right answer.\"\"\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "5hBMK-lfTBFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Zero_Shot_CoT = \"\"\"what will be the impact of Artificial Intelligence on human reasoning and learning in the near future?\n",
        "\n",
        "Let's think step by step.\"\"\""
      ],
      "metadata": {
        "id": "91Xs2qKaTBZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt5 = vicunaQ4KM_CT(Zero_Shot_CoT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "GnjDNQVzTCQf",
        "outputId": "6a75b585-ce76-4c6a-ae93-1bbb44ec97f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;91mPrompt: what will be the impact of Artificial Intelligence on human reasoning \u001b[0m\n",
              "\u001b[1;3;91mand learning in the near future?\u001b[0m\n",
              "\n",
              "\u001b[1;3;91mLet's think step by step.\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Prompt: what will be the impact of Artificial Intelligence on human reasoning </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">and learning in the near future?</span>\n",
              "\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Let's think step by step.</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3mNumber of tokens in the  prompt: \u001b[0m\u001b[1;3;36m70\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Number of tokens in the  prompt: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">70</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3mNumber of tokens in the  answer: \u001b[0m\u001b[1;3;36m628\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Number of tokens in the  answer: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">628</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sure, I can provide my insights on how artificial intelligence (AI) may impact  \n",
              "human reasoning and learning in the near future. Here are some steps we could   \n",
              "take to explore this question:                                                  \n",
              "\n",
              "\u001b[1;33m 1 \u001b[0mUnderstand what AI is and its capabilities: Firstly, it's important to       \n",
              "\u001b[1;33m   \u001b[0munderstand that AI refers to computer systems capable of performing tasks    \n",
              "\u001b[1;33m   \u001b[0mthat typically require human intelligence, such as perception, speech        \n",
              "\u001b[1;33m   \u001b[0mrecognition, decision-making, and language translation. While some tasks are \n",
              "\u001b[1;33m   \u001b[0malready being performed by AI systems with high accuracy, there are still    \n",
              "\u001b[1;33m   \u001b[0mmany limitations in terms of creativity, empathy, and understanding context. \n",
              "\u001b[1;33m 2 \u001b[0mAnalyze the impact of AI on reasoning: One potential impact of AI on human   \n",
              "\u001b[1;33m   \u001b[0mreasoning is that it could challenge our ability to think critically and     \n",
              "\u001b[1;33m   \u001b[0mcreatively. For example, if we rely too heavily on AI systems for            \n",
              "\u001b[1;33m   \u001b[0mdecision-making or problem-solving, we may become less adept at using our own\n",
              "\u001b[1;33m   \u001b[0mreasoning skills. However, this depends on how AI systems are designed and   \n",
              "\u001b[1;33m   \u001b[0mused in practice.                                                            \n",
              "\u001b[1;33m 3 \u001b[0mConsider the impact of AI on learning: Another potential impact of AI on     \n",
              "\u001b[1;33m   \u001b[0mhuman learning is that it could change the way we access information and     \n",
              "\u001b[1;33m   \u001b[0mlearn new things. For example, if we have access to a vast library of        \n",
              "\u001b[1;33m   \u001b[0mknowledge stored in an AI system, we may be able to learn more efficiently by\n",
              "\u001b[1;33m   \u001b[0masking questions or exploring different topics with greater ease than before.\n",
              "\u001b[1;33m   \u001b[0mHowever, this also raises concerns about whether humans will become too      \n",
              "\u001b[1;33m   \u001b[0mreliant on technology for learning and forget how to think independently.    \n",
              "\u001b[1;33m 4 \u001b[0mExplore potential benefits of AI in education: One potential benefit of using\n",
              "\u001b[1;33m   \u001b[0mAI systems in education is that they could provide personalized learning     \n",
              "\u001b[1;33m   \u001b[0mexperiences tailored to individual needs. This could help students learn more\n",
              "\u001b[1;33m   \u001b[0meffectively, particularly those who struggle with traditional educational    \n",
              "\u001b[1;33m   \u001b[0mmethods. Additionally, AI systems could assist teachers by automating        \n",
              "\u001b[1;33m   \u001b[0madministrative tasks and providing insights into student progress, allowing  \n",
              "\u001b[1;33m   \u001b[0mthem to focus on teaching rather than paperwork.                             \n",
              "\u001b[1;33m 5 \u001b[0mAssess the potential risks of over-reliance on AI: There are also potential  \n",
              "\u001b[1;33m   \u001b[0mrisks associated with over-reliance on AI in education or reasoning. For     \n",
              "\u001b[1;33m   \u001b[0mexample, if we become too reliant on AI systems for decision-making or       \n",
              "\u001b[1;33m   \u001b[0mproblem-solving, we may lose our ability to think critically and creatively, \n",
              "\u001b[1;33m   \u001b[0mwhich could have negative consequences in a variety of contexts.             \n",
              "\u001b[1;33m   \u001b[0mAdditionally, there are concerns about bias and discrimination embedded in AI\n",
              "\u001b[1;33m   \u001b[0malgorithms that could perpetuate existing social inequalities if not properly\n",
              "\u001b[1;33m   \u001b[0maddressed.                                                                   \n",
              "\u001b[1;33m 6 \u001b[0mConsider the role of human values in AI development: Finally, it's important \n",
              "\u001b[1;33m   \u001b[0mto consider the role of human values in developing AI systems that support   \n",
              "\u001b[1;33m   \u001b[0mrather than hinder human reasoning and learning. This includes ensuring that \n",
              "\u001b[1;33m   \u001b[0mAI algorithms are transparent and explainable so that humans can understand  \n",
              "\u001b[1;33m   \u001b[0mhow decisions are being made. Additionally, there needs to be a concerted    \n",
              "\u001b[1;33m   \u001b[0meffort to address ethical concerns around data privacy, bias, and            \n",
              "\u001b[1;33m   \u001b[0maccountability in the development of AI systems.                             \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sure, I can provide my insights on how artificial intelligence (AI) may impact  \n",
              "human reasoning and learning in the near future. Here are some steps we could   \n",
              "take to explore this question:                                                  \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span>Understand what AI is and its capabilities: Firstly, it's important to       \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>understand that AI refers to computer systems capable of performing tasks    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>that typically require human intelligence, such as perception, speech        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>recognition, decision-making, and language translation. While some tasks are \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>already being performed by AI systems with high accuracy, there are still    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>many limitations in terms of creativity, empathy, and understanding context. \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span>Analyze the impact of AI on reasoning: One potential impact of AI on human   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>reasoning is that it could challenge our ability to think critically and     \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>creatively. For example, if we rely too heavily on AI systems for            \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>decision-making or problem-solving, we may become less adept at using our own\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>reasoning skills. However, this depends on how AI systems are designed and   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>used in practice.                                                            \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span>Consider the impact of AI on learning: Another potential impact of AI on     \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>human learning is that it could change the way we access information and     \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>learn new things. For example, if we have access to a vast library of        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>knowledge stored in an AI system, we may be able to learn more efficiently by\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>asking questions or exploring different topics with greater ease than before.\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>However, this also raises concerns about whether humans will become too      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>reliant on technology for learning and forget how to think independently.    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span>Explore potential benefits of AI in education: One potential benefit of using\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>AI systems in education is that they could provide personalized learning     \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>experiences tailored to individual needs. This could help students learn more\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>effectively, particularly those who struggle with traditional educational    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>methods. Additionally, AI systems could assist teachers by automating        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>administrative tasks and providing insights into student progress, allowing  \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>them to focus on teaching rather than paperwork.                             \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 5 </span>Assess the potential risks of over-reliance on AI: There are also potential  \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>risks associated with over-reliance on AI in education or reasoning. For     \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>example, if we become too reliant on AI systems for decision-making or       \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>problem-solving, we may lose our ability to think critically and creatively, \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>which could have negative consequences in a variety of contexts.             \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>Additionally, there are concerns about bias and discrimination embedded in AI\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>algorithms that could perpetuate existing social inequalities if not properly\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>addressed.                                                                   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 6 </span>Consider the role of human values in AI development: Finally, it's important \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>to consider the role of human values in developing AI systems that support   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>rather than hinder human reasoning and learning. This includes ensuring that \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>AI algorithms are transparent and explainable so that humans can understand  \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>how decisions are being made. Additionally, there needs to be a concerted    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>effort to address ethical concerns around data privacy, bias, and            \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>accountability in the development of AI systems.                             \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;32m Generated by Vicuna-7b in \u001b[0m\u001b[1;3;32m0:06:58\u001b[0m\u001b[1;3;32m.\u001b[0m\u001b[1;3;32m430866\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold; font-style: italic\"> Generated by Vicuna-7b in 0:06:58.430866</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;5;21m ---\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0000ff; text-decoration-color: #0000ff\"> ---</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Zero_Shot_CoT_APE = \"\"\"what will be the impact of Artificial Intelligence on human reasoning and learning in the near future?\n",
        "\n",
        "Let's work this out in a step by step way to be sure we have the right answer.\"\"\""
      ],
      "metadata": {
        "id": "y2yijVUcTCE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt6 = vicunaQ4KM_CT(Zero_Shot_CoT_APE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "id": "dPbNAbbOVaRX",
        "outputId": "eedaff4b-c11c-41c6-b26c-c1304427f88c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;91mPrompt: what will be the impact of Artificial Intelligence on human reasoning \u001b[0m\n",
              "\u001b[1;3;91mand learning in the near future?\u001b[0m\n",
              "\n",
              "\u001b[1;3;91mLet's work this out in a step by step way to be sure we have the right answer.\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Prompt: what will be the impact of Artificial Intelligence on human reasoning </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">and learning in the near future?</span>\n",
              "\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Let's work this out in a step by step way to be sure we have the right answer.</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3mNumber of tokens in the  prompt: \u001b[0m\u001b[1;3;36m83\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Number of tokens in the  prompt: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">83</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3mNumber of tokens in the  answer: \u001b[0m\u001b[1;3;36m665\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Number of tokens in the  answer: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">665</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sure, I can help you explore that question! Here are some steps we could follow:\n",
              "\n",
              "\u001b[1;33m 1 \u001b[0mUnderstand what artificial intelligence (AI) is and how it works: We need to \n",
              "\u001b[1;33m   \u001b[0mdefine what we mean by \"artificial intelligence\" before we can consider its  \n",
              "\u001b[1;33m   \u001b[0mimpact on human reasoning and learning. AI refers to a range of              \n",
              "\u001b[1;33m   \u001b[0mcomputer-based techniques that allow machines or computers to mimic human    \n",
              "\u001b[1;33m   \u001b[0mbehavior, learn from data, reason using algorithms, and make decisions       \n",
              "\u001b[1;33m   \u001b[0mwithout being explicitly programmed for each task.                           \n",
              "\u001b[1;33m 2 \u001b[0mAnalyze the current state of AI: We need to understand where AI is currently \n",
              "\u001b[1;33m   \u001b[0mat in terms of its capabilities and limitations. While AI has made           \n",
              "\u001b[1;33m   \u001b[0msignificant progress over the past few years, it still lacks some critical   \n",
              "\u001b[1;33m   \u001b[0maspects that are essential for human reasoning and learning, such as         \n",
              "\u001b[1;33m   \u001b[0memotional intelligence, creativity, and common sense reasoning.              \n",
              "\u001b[1;33m 3 \u001b[0mConsider how AI can impact human reasoning: If we assume that AI will        \n",
              "\u001b[1;33m   \u001b[0mcontinue to advance in the near future, what could be its potential impact on\n",
              "\u001b[1;33m   \u001b[0mhuman reasoning? One possibility is that AI may help humans reason more      \n",
              "\u001b[1;33m   \u001b[0mefficiently by providing faster and more accurate data analysis, pattern     \n",
              "\u001b[1;33m   \u001b[0mrecognition, and prediction. However, it's also possible that excessive      \n",
              "\u001b[1;33m   \u001b[0mreliance on AI might lead to a decrease in critical thinking skills as humans\n",
              "\u001b[1;33m   \u001b[0mbecome overly dependent on technology for decision-making.                   \n",
              "\u001b[1;33m 4 \u001b[0mExplore the impact of AI on human learning: How could AI affect human        \n",
              "\u001b[1;33m   \u001b[0mlearning? One potential benefit is that AI could personalize and adapt       \n",
              "\u001b[1;33m   \u001b[0meducational content based on each individual's unique needs, preferences, and\n",
              "\u001b[1;33m   \u001b[0mlearning styles. This might lead to more effective and efficient learning for\n",
              "\u001b[1;33m   \u001b[0mmany individuals. However, there are also concerns about the role of AI in   \n",
              "\u001b[1;33m   \u001b[0mreplacing teachers or exacerbating existing social inequalities in access to \n",
              "\u001b[1;33m   \u001b[0meducation and job opportunities.                                             \n",
              "\u001b[1;33m 5 \u001b[0mConsider potential ethical implications: As we explore the impacts of AI on  \n",
              "\u001b[1;33m   \u001b[0mhuman reasoning and learning, it's crucial to consider potential ethical     \n",
              "\u001b[1;33m   \u001b[0mimplications. For example, who will be responsible for ensuring that AI      \n",
              "\u001b[1;33m   \u001b[0msystems are fair, unbiased, and transparent? How can we ensure that AI is    \n",
              "\u001b[1;33m   \u001b[0mused in ways that promote social good rather than harm?                      \n",
              "\u001b[1;33m 6 \u001b[0mMake predictions about the future: Based on our analysis of current trends   \n",
              "\u001b[1;33m   \u001b[0mand potential impacts, what might the future look like for human reasoning   \n",
              "\u001b[1;33m   \u001b[0mand learning with AI integration? It's difficult to predict exactly how      \n",
              "\u001b[1;33m   \u001b[0mthings will play out, but one possible scenario is that humans may need to   \n",
              "\u001b[1;33m   \u001b[0madapt their skills and knowledge base to work alongside AI systems. This     \n",
              "\u001b[1;33m   \u001b[0mcould involve reorienting education towards teaching critical thinking,      \n",
              "\u001b[1;33m   \u001b[0mcreativity, and emotional intelligence in order for individuals to           \n",
              "\u001b[1;33m   \u001b[0meffectively collaborate with AI tools.                                       \n",
              "\u001b[1;33m 7 \u001b[0mRevisit the question: Finally, we can revisit our initial question about the \n",
              "\u001b[1;33m   \u001b[0mimpact of AI on human reasoning and learning. Based on what we've explored   \n",
              "\u001b[1;33m   \u001b[0mabove, it seems that while there may be some benefits and challenges         \n",
              "\u001b[1;33m   \u001b[0massociated with integrating AI into education and decision-making processes, \n",
              "\u001b[1;33m   \u001b[0multimately the extent to which AI will influence human behavior depends on   \n",
              "\u001b[1;33m   \u001b[0mhow it is designed, implemented, and regulated by society as a whole.        \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sure, I can help you explore that question! Here are some steps we could follow:\n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span>Understand what artificial intelligence (AI) is and how it works: We need to \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>define what we mean by \"artificial intelligence\" before we can consider its  \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>impact on human reasoning and learning. AI refers to a range of              \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>computer-based techniques that allow machines or computers to mimic human    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>behavior, learn from data, reason using algorithms, and make decisions       \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>without being explicitly programmed for each task.                           \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span>Analyze the current state of AI: We need to understand where AI is currently \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>at in terms of its capabilities and limitations. While AI has made           \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>significant progress over the past few years, it still lacks some critical   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>aspects that are essential for human reasoning and learning, such as         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>emotional intelligence, creativity, and common sense reasoning.              \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span>Consider how AI can impact human reasoning: If we assume that AI will        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>continue to advance in the near future, what could be its potential impact on\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>human reasoning? One possibility is that AI may help humans reason more      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>efficiently by providing faster and more accurate data analysis, pattern     \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>recognition, and prediction. However, it's also possible that excessive      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>reliance on AI might lead to a decrease in critical thinking skills as humans\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>become overly dependent on technology for decision-making.                   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span>Explore the impact of AI on human learning: How could AI affect human        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>learning? One potential benefit is that AI could personalize and adapt       \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>educational content based on each individual's unique needs, preferences, and\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>learning styles. This might lead to more effective and efficient learning for\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>many individuals. However, there are also concerns about the role of AI in   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>replacing teachers or exacerbating existing social inequalities in access to \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>education and job opportunities.                                             \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 5 </span>Consider potential ethical implications: As we explore the impacts of AI on  \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>human reasoning and learning, it's crucial to consider potential ethical     \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>implications. For example, who will be responsible for ensuring that AI      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>systems are fair, unbiased, and transparent? How can we ensure that AI is    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>used in ways that promote social good rather than harm?                      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 6 </span>Make predictions about the future: Based on our analysis of current trends   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>and potential impacts, what might the future look like for human reasoning   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>and learning with AI integration? It's difficult to predict exactly how      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>things will play out, but one possible scenario is that humans may need to   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>adapt their skills and knowledge base to work alongside AI systems. This     \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>could involve reorienting education towards teaching critical thinking,      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>creativity, and emotional intelligence in order for individuals to           \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>effectively collaborate with AI tools.                                       \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 7 </span>Revisit the question: Finally, we can revisit our initial question about the \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>impact of AI on human reasoning and learning. Based on what we've explored   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>above, it seems that while there may be some benefits and challenges         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>associated with integrating AI into education and decision-making processes, \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>ultimately the extent to which AI will influence human behavior depends on   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>how it is designed, implemented, and regulated by society as a whole.        \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;32m Generated by Vicuna-7b in \u001b[0m\u001b[1;3;32m0:07:32\u001b[0m\u001b[1;3;32m.\u001b[0m\u001b[1;3;32m049468\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold; font-style: italic\"> Generated by Vicuna-7b in 0:07:32.049468</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;5;21m ---\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0000ff; text-decoration-color: #0000ff\"> ---</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### name: 'Tree of Thought V2',\n",
        "description: \"The Tree of Thoughts (ToT) framework improves language models' problem-solving abilities by allowing deliberate decision making through exploration and strategic lookahead\",\n",
        "paper: 'https://arxiv.org/abs/2305.10601',\n",
        "content:\n",
        "```\n",
        "\"\"\"Simulate three brilliant, logical experts collaboratively answering a question.\n",
        "Each one verbosely explains their thought process in real-time, considering the prior explanations of others and openly acknowledging mistakes.\n",
        "At each step, whenever possible, each expert refines and builds upon the thoughts of others, acknowledging their contributions.\n",
        "They continue until there is a definitive answer to the question.\n",
        "For clarity, your entire response should be in a markdown table. The question is...\n",
        "\n",
        "{question}\n",
        "\"\"\"\n",
        "```\n"
      ],
      "metadata": {
        "id": "my1BNhTMTCuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ToT_V2 = \"\"\"Simulate three brilliant, logical experts collaboratively answering a question.\n",
        "Each one verbosely explains their thought process in real-time, considering the prior explanations of others and openly acknowledging mistakes.\n",
        "At each step, whenever possible, each expert refines and builds upon the thoughts of others, acknowledging their contributions.\n",
        "They continue until there is a definitive answer to the question.\n",
        "For clarity, your entire response should be in a markdown table. The question is...\n",
        "\n",
        "How can we fix global climate change?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JObswIL0hoW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt7 = vicunaQ4KM_CT(ToT_V2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yGGSxFwXTDMf",
        "outputId": "173c397c-509e-4a40-fe89-452a8a51587d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;91mPrompt: Simulate three brilliant, logical experts collaboratively answering a \u001b[0m\n",
              "\u001b[1;3;91mquestion.\u001b[0m\n",
              "\u001b[1;3;91mEach one verbosely explains their thought process in real-time, considering the \u001b[0m\n",
              "\u001b[1;3;91mprior explanations of others and openly acknowledging mistakes.\u001b[0m\n",
              "\u001b[1;3;91mAt each step, whenever possible, each expert refines and builds upon the \u001b[0m\n",
              "\u001b[1;3;91mthoughts of others, acknowledging their contributions.\u001b[0m\n",
              "\u001b[1;3;91mThey continue until there is a definitive answer to the question.\u001b[0m\n",
              "\u001b[1;3;91mFor clarity, your entire response should be in a markdown table. The question \u001b[0m\n",
              "\u001b[1;3;91mis\u001b[0m\u001b[1;3;91m...\u001b[0m\n",
              "\n",
              "\u001b[1;3;91mHow can we fix global climate change?\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Prompt: Simulate three brilliant, logical experts collaboratively answering a </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">question.</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Each one verbosely explains their thought process in real-time, considering the </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">prior explanations of others and openly acknowledging mistakes.</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">At each step, whenever possible, each expert refines and builds upon the </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">thoughts of others, acknowledging their contributions.</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">They continue until there is a definitive answer to the question.</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">For clarity, your entire response should be in a markdown table. The question </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">is...</span>\n",
              "\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">How can we fix global climate change?</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3mNumber of tokens in the  prompt: \u001b[0m\u001b[1;3;36m152\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Number of tokens in the  prompt: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">152</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3mNumber of tokens in the  answer: \u001b[0m\u001b[1;3;36m366\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Number of tokens in the  answer: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">366</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\n",
              "\n",
              "\n",
              "                                                                                \n",
              " \u001b[1m \u001b[0m\u001b[1mExpert 1\u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mExpert 2\u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mExpert 3\u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mAnswer\u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m \n",
              " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
              "  \u001b[3mClimate change is\u001b[0m   \u001b[3mAgreed.\u001b[0m\u001b[3mWe also \u001b[0m     \u001b[3mExactly.\u001b[0m\u001b[3mIn \u001b[0m         The key to        \n",
              "  \u001b[3mcaused by the \u001b[0m      \u001b[3mneed to consider \u001b[0m   \u001b[3maddition, we must\u001b[0m   fixing global     \n",
              "  \u001b[3moveruse of fossil\u001b[0m   \u001b[3mthe role of \u001b[0m        \u001b[3maddress the issue\u001b[0m   climate change    \n",
              "  \u001b[3mfuels, which \u001b[0m       \u001b[3mdeforestation in \u001b[0m   \u001b[3mof carbon \u001b[0m          is transitioning  \n",
              "  \u001b[3mrelease carbon \u001b[0m     \u001b[3mcontributing to \u001b[0m    \u001b[3memissions from \u001b[0m     away from fossil  \n",
              "  \u001b[3mdioxide and other\u001b[0m   \u001b[3mclimate change. \u001b[0m    \u001b[3mtransportation \u001b[0m     fuels and         \n",
              "  \u001b[3mgreenhouse gases \u001b[0m   \u001b[3mWe can combat \u001b[0m      \u001b[3mand industry. One\u001b[0m   towards clean     \n",
              "  \u001b[3minto the \u001b[0m           \u001b[3mthis by promoting\u001b[0m   \u001b[3msolution is to \u001b[0m     energy sources    \n",
              "  \u001b[3matmosphere. We \u001b[0m     \u001b[3mreforestation \u001b[0m      \u001b[3mdevelop more \u001b[0m       like solar,       \n",
              "  \u001b[3mneed to \u001b[0m            \u001b[3mefforts, \u001b[0m           \u001b[3mefficient \u001b[0m          wind,             \n",
              "  \u001b[3mtransition to \u001b[0m      \u001b[3mespecially in \u001b[0m      \u001b[3mvehicles and \u001b[0m       hydroelectric     \n",
              "  \u001b[3mclean energy \u001b[0m       \u001b[3mareas that have \u001b[0m    \u001b[3mindustrial \u001b[0m         power, and        \n",
              "  \u001b[3msources like \u001b[0m       \u001b[3mbeen affected by \u001b[0m   \u001b[3mprocesses that \u001b[0m     geothermal        \n",
              "  \u001b[3msolar, wind, \u001b[0m       \u001b[3mlogging or forest\u001b[0m   \u001b[3mreduce emissions,\u001b[0m   energy. We must   \n",
              "  \u001b[3mhydroelectric \u001b[0m      \u001b[3mfires.\u001b[0m              \u001b[3mas well as \u001b[0m         also address      \n",
              "  \u001b[3mpower, and \u001b[0m                             \u001b[3minvesting in \u001b[0m       deforestation,    \n",
              "  \u001b[3mgeothermal \u001b[0m                             \u001b[3mpublic transit \u001b[0m     promote           \n",
              "  \u001b[3menergy.\u001b[0m\u001b[3mFirstly, \u001b[0m                        \u001b[3msystems and \u001b[0m        reforestation     \n",
              "  \u001b[3mwe must invest in\u001b[0m                       \u001b[3mencouraging \u001b[0m        efforts, and      \n",
              "  \u001b[3mresearch and \u001b[0m                           \u001b[3mtelecommuting \u001b[0m      work on reducing  \n",
              "  \u001b[3mdevelopment for \u001b[0m                        \u001b[3mwhen possible.\u001b[0m      carbon emissions  \n",
              "  \u001b[3mrenewable energy \u001b[0m                                           in                \n",
              "  \u001b[3mtechnologies, so \u001b[0m                                           transportation    \n",
              "  \u001b[3mthat they become \u001b[0m                                           and industry      \n",
              "  \u001b[3mmore efficient \u001b[0m                                             through more      \n",
              "  \u001b[3mand \u001b[0m                                                        efficient         \n",
              "  \u001b[3mcost-effective. \u001b[0m                                            vehicles and      \n",
              "  \u001b[3mSecondly, we \u001b[0m                                               industrial        \n",
              "  \u001b[3mshould implement \u001b[0m                                           processes as      \n",
              "  \u001b[3mpolicies and \u001b[0m                                               well as public    \n",
              "  \u001b[3mregulations that \u001b[0m                                           transit systems   \n",
              "  \u001b[3mincentivize the \u001b[0m                                            and               \n",
              "  \u001b[3muse of clean \u001b[0m                                               telecommuting     \n",
              "  \u001b[3menergy sources by\u001b[0m                                           when possible.    \n",
              "  \u001b[3mreducing tariffs \u001b[0m                                                             \n",
              "  \u001b[3mon them and \u001b[0m                                                                  \n",
              "  \u001b[3mincreasing taxes \u001b[0m                                                             \n",
              "  \u001b[3mon fossil fuels.\u001b[0m                                                              \n",
              "                                                                                \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "\n",
              "\n",
              "                                                                                \n",
              " <span style=\"font-weight: bold\"> Expert 1          </span> <span style=\"font-weight: bold\"> Expert 2          </span> <span style=\"font-weight: bold\"> Expert 3          </span> <span style=\"font-weight: bold\"> Answer           </span> \n",
              " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
              "  <span style=\"font-style: italic\">Climate change is</span>   <span style=\"font-style: italic\">Agreed.We also </span>     <span style=\"font-style: italic\">Exactly.In </span>         The key to        \n",
              "  <span style=\"font-style: italic\">caused by the </span>      <span style=\"font-style: italic\">need to consider </span>   <span style=\"font-style: italic\">addition, we must</span>   fixing global     \n",
              "  <span style=\"font-style: italic\">overuse of fossil</span>   <span style=\"font-style: italic\">the role of </span>        <span style=\"font-style: italic\">address the issue</span>   climate change    \n",
              "  <span style=\"font-style: italic\">fuels, which </span>       <span style=\"font-style: italic\">deforestation in </span>   <span style=\"font-style: italic\">of carbon </span>          is transitioning  \n",
              "  <span style=\"font-style: italic\">release carbon </span>     <span style=\"font-style: italic\">contributing to </span>    <span style=\"font-style: italic\">emissions from </span>     away from fossil  \n",
              "  <span style=\"font-style: italic\">dioxide and other</span>   <span style=\"font-style: italic\">climate change. </span>    <span style=\"font-style: italic\">transportation </span>     fuels and         \n",
              "  <span style=\"font-style: italic\">greenhouse gases </span>   <span style=\"font-style: italic\">We can combat </span>      <span style=\"font-style: italic\">and industry. One</span>   towards clean     \n",
              "  <span style=\"font-style: italic\">into the </span>           <span style=\"font-style: italic\">this by promoting</span>   <span style=\"font-style: italic\">solution is to </span>     energy sources    \n",
              "  <span style=\"font-style: italic\">atmosphere. We </span>     <span style=\"font-style: italic\">reforestation </span>      <span style=\"font-style: italic\">develop more </span>       like solar,       \n",
              "  <span style=\"font-style: italic\">need to </span>            <span style=\"font-style: italic\">efforts, </span>           <span style=\"font-style: italic\">efficient </span>          wind,             \n",
              "  <span style=\"font-style: italic\">transition to </span>      <span style=\"font-style: italic\">especially in </span>      <span style=\"font-style: italic\">vehicles and </span>       hydroelectric     \n",
              "  <span style=\"font-style: italic\">clean energy </span>       <span style=\"font-style: italic\">areas that have </span>    <span style=\"font-style: italic\">industrial </span>         power, and        \n",
              "  <span style=\"font-style: italic\">sources like </span>       <span style=\"font-style: italic\">been affected by </span>   <span style=\"font-style: italic\">processes that </span>     geothermal        \n",
              "  <span style=\"font-style: italic\">solar, wind, </span>       <span style=\"font-style: italic\">logging or forest</span>   <span style=\"font-style: italic\">reduce emissions,</span>   energy. We must   \n",
              "  <span style=\"font-style: italic\">hydroelectric </span>      <span style=\"font-style: italic\">fires.</span>              <span style=\"font-style: italic\">as well as </span>         also address      \n",
              "  <span style=\"font-style: italic\">power, and </span>                             <span style=\"font-style: italic\">investing in </span>       deforestation,    \n",
              "  <span style=\"font-style: italic\">geothermal </span>                             <span style=\"font-style: italic\">public transit </span>     promote           \n",
              "  <span style=\"font-style: italic\">energy.Firstly, </span>                        <span style=\"font-style: italic\">systems and </span>        reforestation     \n",
              "  <span style=\"font-style: italic\">we must invest in</span>                       <span style=\"font-style: italic\">encouraging </span>        efforts, and      \n",
              "  <span style=\"font-style: italic\">research and </span>                           <span style=\"font-style: italic\">telecommuting </span>      work on reducing  \n",
              "  <span style=\"font-style: italic\">development for </span>                        <span style=\"font-style: italic\">when possible.</span>      carbon emissions  \n",
              "  <span style=\"font-style: italic\">renewable energy </span>                                           in                \n",
              "  <span style=\"font-style: italic\">technologies, so </span>                                           transportation    \n",
              "  <span style=\"font-style: italic\">that they become </span>                                           and industry      \n",
              "  <span style=\"font-style: italic\">more efficient </span>                                             through more      \n",
              "  <span style=\"font-style: italic\">and </span>                                                        efficient         \n",
              "  <span style=\"font-style: italic\">cost-effective. </span>                                            vehicles and      \n",
              "  <span style=\"font-style: italic\">Secondly, we </span>                                               industrial        \n",
              "  <span style=\"font-style: italic\">should implement </span>                                           processes as      \n",
              "  <span style=\"font-style: italic\">policies and </span>                                               well as public    \n",
              "  <span style=\"font-style: italic\">regulations that </span>                                           transit systems   \n",
              "  <span style=\"font-style: italic\">incentivize the </span>                                            and               \n",
              "  <span style=\"font-style: italic\">use of clean </span>                                               telecommuting     \n",
              "  <span style=\"font-style: italic\">energy sources by</span>                                           when possible.    \n",
              "  <span style=\"font-style: italic\">reducing tariffs </span>                                                             \n",
              "  <span style=\"font-style: italic\">on them and </span>                                                                  \n",
              "  <span style=\"font-style: italic\">increasing taxes </span>                                                             \n",
              "  <span style=\"font-style: italic\">on fossil fuels.</span>                                                              \n",
              "                                                                                \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;32m Generated by Vicuna-7b in \u001b[0m\u001b[1;3;32m0:04:54\u001b[0m\u001b[1;3;32m.\u001b[0m\u001b[1;3;32m620494\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold; font-style: italic\"> Generated by Vicuna-7b in 0:04:54.620494</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;5;21m ---\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0000ff; text-decoration-color: #0000ff\"> ---</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### name: 'Summarization Into List',\n",
        "description: `This prompt asks the LLM to summarize a given text into a list of bullet points.`,\n",
        "Promt Template:\n",
        "```\n",
        "\"\"\"Write a concise summary of the following text delimited by triple backquotes.\n",
        "Return your response in bullet points which covers the key points of the text.\n",
        "\n",
        "```\n",
        "{text}\n",
        "```\n",
        "\n",
        "BULLET POINT SUMMARY:\"\"\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "b09G0ZX-iq17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SummarizToList = \"\"\"Write a concise summary of the following text delimited by triple backquotes.\n",
        "Return your response in bullet points which covers the key points of the text.\n",
        "\n",
        "```\n",
        "This study from March 2023 takes a simple yet novel approach to prompt engineering by automatically generating\n",
        "prompts based on the desired input and output. In a recent article I considered the future of prompt engineering,\n",
        "and the possibility of soft prompts (prompt tuning). I argued that user context, ambiguity and user intent all play\n",
        "an important role in any conversational UI. User intent, context, ambiguity and disambiguation are all part and\n",
        "parcel of any conversation. The question is, can this approach accelerate the process where manually wording\n",
        "prompts fade into the background and interaction with the LLM is based on contextual example input and output\n",
        "datasets? What I like about this approach, is that context, and user intent can be mapped, while also taking into\n",
        "consideration possible ambiguity. Yet manually crafting prompts is tedious in the sense of trying to word a prompt\n",
        "in such a way to engender a desired response from the LLM. Focussing on prompt engineering also does not take into\n",
        "consideration an array of possible user inputs. Data Management will always be part of LLM applications. APE offers\n",
        "an alternative approach to prompt engineering, where via input and matching output examples, prompts can be\n",
        "generated on the fly. We define “prompt engineering” as optimising the language in a prompt in order to elicit the\n",
        "best possible performance. Notably, this does not include prompts that chain multiple LLM queries together or give\n",
        "the LLM access to external tools. ~ Source The basic notebook below shows how Automatic Prompt Engineering (APE)\n",
        "can be used to generate prompts based on a small input data set, a list of expected outputs and a prompt template.\n",
        "APE performs this in two steps: A LLM is used to generate a set of candidate prompts. A prompt evaluation function\n",
        "considers the quality of each candidate prompt; returning the prompt with the highest evaluation score. A practical\n",
        "implementation is, via a human-in-the-loop approach, prompts can be marked up and marked down for use on terms of\n",
        "accuracy and correctness.\n",
        "```\n",
        "\n",
        "BULLET POINT SUMMARY:\"\"\""
      ],
      "metadata": {
        "id": "OEd2WVxnTB9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt8 = vicunaQ4KM_CT(SummarizToList)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sOEVQ5wOTBzP",
        "outputId": "2a56a09d-bb5c-4ecd-815e-e21cdd994389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;91mPrompt: Write a concise summary of the following text delimited by triple \u001b[0m\n",
              "\u001b[1;3;91mbackquotes.\u001b[0m\n",
              "\u001b[1;3;91mReturn your response in bullet points which covers the key points of the text.\u001b[0m\n",
              "\n",
              "\u001b[1;3;91m```\u001b[0m\n",
              "\u001b[1;3;91mThis study from March \u001b[0m\u001b[1;3;91m2023\u001b[0m\u001b[1;3;91m takes a simple yet novel approach to prompt \u001b[0m\n",
              "\u001b[1;3;91mengineering by automatically generating\u001b[0m\n",
              "\u001b[1;3;91mprompts based on the desired input and output. In a recent article I considered \u001b[0m\n",
              "\u001b[1;3;91mthe future of prompt engineering,\u001b[0m\n",
              "\u001b[1;3;91mand the possibility of soft prompts \u001b[0m\u001b[1;3;91m(\u001b[0m\u001b[1;3;91mprompt tuning\u001b[0m\u001b[1;3;91m)\u001b[0m\u001b[1;3;91m. I argued that user context,\u001b[0m\n",
              "\u001b[1;3;91mambiguity and user intent all play\u001b[0m\n",
              "\u001b[1;3;91man important role in any conversational UI. User intent, context, ambiguity and \u001b[0m\n",
              "\u001b[1;3;91mdisambiguation are all part and\u001b[0m\n",
              "\u001b[1;3;91mparcel of any conversation. The question is, can this approach accelerate the \u001b[0m\n",
              "\u001b[1;3;91mprocess where manually wording\u001b[0m\n",
              "\u001b[1;3;91mprompts fade into the background and interaction with the LLM is based on \u001b[0m\n",
              "\u001b[1;3;91mcontextual example input and output\u001b[0m\n",
              "\u001b[1;3;91mdatasets? What I like about this approach, is that context, and user intent can \u001b[0m\n",
              "\u001b[1;3;91mbe mapped, while also taking into\u001b[0m\n",
              "\u001b[1;3;91mconsideration possible ambiguity. Yet manually crafting prompts is tedious in \u001b[0m\n",
              "\u001b[1;3;91mthe sense of trying to word a prompt\u001b[0m\n",
              "\u001b[1;3;91min such a way to engender a desired response from the LLM. Focussing on prompt \u001b[0m\n",
              "\u001b[1;3;91mengineering also does not take into\u001b[0m\n",
              "\u001b[1;3;91mconsideration an array of possible user inputs. Data Management will always be \u001b[0m\n",
              "\u001b[1;3;91mpart of LLM applications. APE offers\u001b[0m\n",
              "\u001b[1;3;91man alternative approach to prompt engineering, where via input and matching \u001b[0m\n",
              "\u001b[1;3;91moutput examples, prompts can be\u001b[0m\n",
              "\u001b[1;3;91mgenerated on the fly. We define “prompt engineering” as optimising the language \u001b[0m\n",
              "\u001b[1;3;91min a prompt in order to elicit the\u001b[0m\n",
              "\u001b[1;3;91mbest possible performance. Notably, this does not include prompts that chain \u001b[0m\n",
              "\u001b[1;3;91mmultiple LLM queries together or give\u001b[0m\n",
              "\u001b[1;3;91mthe LLM access to external tools. ~ Source The basic notebook below shows how \u001b[0m\n",
              "\u001b[1;3;91mAutomatic Prompt Engineering \u001b[0m\u001b[1;3;91m(\u001b[0m\u001b[1;3;91mAPE\u001b[0m\u001b[1;3;91m)\u001b[0m\n",
              "\u001b[1;3;91mcan be used to generate prompts based on a small input data set, a list of \u001b[0m\n",
              "\u001b[1;3;91mexpected outputs and a prompt template.\u001b[0m\n",
              "\u001b[1;3;91mAPE performs this in two steps: A LLM is used to generate a set of candidate \u001b[0m\n",
              "\u001b[1;3;91mprompts. A prompt evaluation function\u001b[0m\n",
              "\u001b[1;3;91mconsiders the quality of each candidate prompt; returning the prompt with the \u001b[0m\n",
              "\u001b[1;3;91mhighest evaluation score. A practical\u001b[0m\n",
              "\u001b[1;3;91mimplementation is, via a human-in-the-loop approach, prompts can be marked up \u001b[0m\n",
              "\u001b[1;3;91mand marked down for use on terms of\u001b[0m\n",
              "\u001b[1;3;91maccuracy and correctness.\u001b[0m\n",
              "\u001b[1;3;91m```\u001b[0m\n",
              "\n",
              "\u001b[1;3;91mBULLET POINT SUMMARY:\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Prompt: Write a concise summary of the following text delimited by triple </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">backquotes.</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Return your response in bullet points which covers the key points of the text.</span>\n",
              "\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">```</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">This study from March 2023 takes a simple yet novel approach to prompt </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">engineering by automatically generating</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">prompts based on the desired input and output. In a recent article I considered </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">the future of prompt engineering,</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">and the possibility of soft prompts (prompt tuning). I argued that user context,</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">ambiguity and user intent all play</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">an important role in any conversational UI. User intent, context, ambiguity and </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">disambiguation are all part and</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">parcel of any conversation. The question is, can this approach accelerate the </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">process where manually wording</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">prompts fade into the background and interaction with the LLM is based on </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">contextual example input and output</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">datasets? What I like about this approach, is that context, and user intent can </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">be mapped, while also taking into</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">consideration possible ambiguity. Yet manually crafting prompts is tedious in </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">the sense of trying to word a prompt</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">in such a way to engender a desired response from the LLM. Focussing on prompt </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">engineering also does not take into</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">consideration an array of possible user inputs. Data Management will always be </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">part of LLM applications. APE offers</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">an alternative approach to prompt engineering, where via input and matching </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">output examples, prompts can be</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">generated on the fly. We define “prompt engineering” as optimising the language </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">in a prompt in order to elicit the</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">best possible performance. Notably, this does not include prompts that chain </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">multiple LLM queries together or give</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">the LLM access to external tools. ~ Source The basic notebook below shows how </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">Automatic Prompt Engineering (APE)</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">can be used to generate prompts based on a small input data set, a list of </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">expected outputs and a prompt template.</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">APE performs this in two steps: A LLM is used to generate a set of candidate </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">prompts. A prompt evaluation function</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">considers the quality of each candidate prompt; returning the prompt with the </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">highest evaluation score. A practical</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">implementation is, via a human-in-the-loop approach, prompts can be marked up </span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">and marked down for use on terms of</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">accuracy and correctness.</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">```</span>\n",
              "\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold; font-style: italic\">BULLET POINT SUMMARY:</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3mNumber of tokens in the  prompt: \u001b[0m\u001b[1;3;36m545\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Number of tokens in the  prompt: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">545</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3mNumber of tokens in the  answer: \u001b[0m\u001b[1;3;36m143\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold; font-style: italic\">Number of tokens in the  answer: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; font-style: italic\">143</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1;33m • \u001b[0mThe study involves Automatic Prompt Engineering (APE) to generate prompts    \n",
              "\u001b[1;33m   \u001b[0mbased on desired input and output, eliminating the need for manually crafting\n",
              "\u001b[1;33m   \u001b[0mthem.                                                                        \n",
              "\u001b[1;33m • \u001b[0mThis approach takes into consideration user context, ambiguity, and intent in\n",
              "\u001b[1;33m   \u001b[0mconversational UIs.                                                          \n",
              "\u001b[1;33m • \u001b[0mThe aim is to accelerate the process of fading away from manually worded     \n",
              "\u001b[1;33m   \u001b[0mprompts and focusing on contextual examples.                                 \n",
              "\u001b[1;33m • \u001b[0mAPE generates prompts on-the-fly through input-output matching examples,     \n",
              "\u001b[1;33m   \u001b[0mrather than considering a range of user inputs.                              \n",
              "\u001b[1;33m • \u001b[0mPrompt engineering involves optimizing language in a prompt for best possible\n",
              "\u001b[1;33m   \u001b[0mperformance without chaining multiple LLM queries or giving access to        \n",
              "\u001b[1;33m   \u001b[0mexternal tools.                                                              \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>The study involves Automatic Prompt Engineering (APE) to generate prompts    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>based on desired input and output, eliminating the need for manually crafting\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>them.                                                                        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>This approach takes into consideration user context, ambiguity, and intent in\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>conversational UIs.                                                          \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>The aim is to accelerate the process of fading away from manually worded     \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>prompts and focusing on contextual examples.                                 \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>APE generates prompts on-the-fly through input-output matching examples,     \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>rather than considering a range of user inputs.                              \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Prompt engineering involves optimizing language in a prompt for best possible\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>performance without chaining multiple LLM queries or giving access to        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>external tools.                                                              \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;3;32m Generated by Vicuna-7b in \u001b[0m\u001b[1;3;32m0:05:48\u001b[0m\u001b[1;3;32m.\u001b[0m\u001b[1;3;32m725935\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold; font-style: italic\"> Generated by Vicuna-7b in 0:05:48.725935</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;5;21m ---\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0000ff; text-decoration-color: #0000ff\"> ---</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}